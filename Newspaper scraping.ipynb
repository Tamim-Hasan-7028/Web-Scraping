{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6739e909-1656-4715-8c6c-025c7560d251",
   "metadata": {},
   "source": [
    "Our mission for this project is to scrap sevaral newspaper by a keyword.\n",
    "Here we choose Banking, Economy and Football keyword. By inputing those keyword, we will scrap news related those keyword from different newspapers automaticly. For this project, we choose Daily Star and Prothom Alo newspaper. After scraping those news, it will store as a csv file where we will have the headline of news, link for the news, publishing time.\n",
    "\n",
    "N.B: This project is based on 15 July, 2024 script. This script may not work later."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f39fa79f-2ace-475f-89d6-9a17fd959ef7",
   "metadata": {},
   "source": [
    "Importing Library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "77920842-aa56-4533-9751-87df2fefc33f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "import time\n",
    "import re\n",
    "from datetime import datetime, timedelta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "0948c9bf-6dac-4c5d-8a0a-253a9089c17f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Category= Football\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wait few seconds for Football category news\n",
      "Pop-up closed.\n",
      "                                             Headline  \\\n",
      "0   Joy, heartbreak splayed across newspapers afte...   \n",
      "1            Messi-blessed Yamal breaks Peleâ€™s record   \n",
      "2                  Thomas Mueller ends Germany career   \n",
      "3   \"Fine margins\" as Southgate's England miss out...   \n",
      "4   Copa triumph takes Messi past every footballer...   \n",
      "5   Scaloni hails Argentina for 'Triple Crown' tri...   \n",
      "6   Joy in the streets of Argentina after Copa vic...   \n",
      "7   Tired Colombia were impacted by delayed start ...   \n",
      "8   Argentina defeat Colombia to win record 16th C...   \n",
      "9                Messi goes off injured in Copa final   \n",
      "10  Spain beat England to win Euro 2024 final with...   \n",
      "11  Crowd chaos as fans kept waiting outside Copa ...   \n",
      "\n",
      "                                                 Link         Time  \\\n",
      "0   https://www.thedailystar.net/sports/sports-spe...      16m ago   \n",
      "1   https://www.thedailystar.net/sports/sports-spe...      38m ago   \n",
      "2   https://www.thedailystar.net/sports/football/n...       1h ago   \n",
      "3   https://www.thedailystar.net/sports/sports-spe...       2h ago   \n",
      "4   https://www.thedailystar.net/sports/sports-spe...       3h ago   \n",
      "5   https://www.thedailystar.net/sports/sports-spe...       3h ago   \n",
      "6   https://www.thedailystar.net/sports/sports-spe...       4h ago   \n",
      "7   https://www.thedailystar.net/sports/sports-spe...       5h ago   \n",
      "8   https://en.prothomalo.com/sports/football/jnn9...  7 hours ago   \n",
      "9   https://en.prothomalo.com/sports/football/jmqf...  7 hours ago   \n",
      "10  https://en.prothomalo.com/sports/football/2pqp...  9 hours ago   \n",
      "11  https://en.prothomalo.com/sports/football/xbqu...  9 hours ago   \n",
      "\n",
      "   Published Time Published Date       Source  Category  \n",
      "0        05:23 PM     15/07/2024   Daily Star  Football  \n",
      "1        05:01 PM     15/07/2024   Daily Star  Football  \n",
      "2        04:39 PM     15/07/2024   Daily Star  Football  \n",
      "3        03:39 PM     15/07/2024   Daily Star  Football  \n",
      "4        02:39 PM     15/07/2024   Daily Star  Football  \n",
      "5        02:39 PM     15/07/2024   Daily Star  Football  \n",
      "6        01:39 PM     15/07/2024   Daily Star  Football  \n",
      "7        12:39 PM     15/07/2024   Daily Star  Football  \n",
      "8        10:39 AM     15/07/2024  Prothom Alo  Football  \n",
      "9        10:39 AM     15/07/2024  Prothom Alo  Football  \n",
      "10       08:39 AM     15/07/2024  Prothom Alo  Football  \n",
      "11       08:39 AM     15/07/2024  Prothom Alo  Football  \n"
     ]
    }
   ],
   "source": [
    "x=input('Category=')\n",
    "print(f\"Wait few seconds for {x} category news\")\n",
    "\n",
    "if x==\"Banking\":\n",
    "    # Initialize the WebDriver\n",
    "    driver = webdriver.Chrome()\n",
    "    driver.get(\"https://www.thedailystar.net/business/banking\")\n",
    "    time.sleep(2)\n",
    "    \n",
    "    \n",
    "    # Define the XPath for the articles\n",
    "    article_xpath = '//div[@class=\"columns small-12 medium-3 large-3\"]'\n",
    "    \n",
    "    # Wait for the articles to be present\n",
    "    WebDriverWait(driver, 10).until(EC.presence_of_all_elements_located((By.XPATH, article_xpath)))\n",
    "    \n",
    "    # List to hold the data\n",
    "    data = []\n",
    "    \n",
    "    # Extract data\n",
    "    articles = driver.find_elements(By.XPATH, article_xpath)\n",
    "    for article in articles:\n",
    "        try:\n",
    "            headline_element = article.find_element(By.XPATH, './/h3[@class=\"title\"]/a')\n",
    "            headline = headline_element.text\n",
    "            link = headline_element.get_attribute('href')\n",
    "            time_element = article.find_element(By.XPATH, './/div[@class=\"card-top color-iron text-12\"]/span[@class=\"interval\"]')\n",
    "            time_text = time_element.text\n",
    "            print(f\"Time Text: {time_text}\")\n",
    "            paper = \"Daily Star\"\n",
    "            category=\"Economy\"\n",
    "            if re.search(r'\\d{1,2}[hm] ago', time_text):\n",
    "            # Calculate the published time\n",
    "                current_time = datetime.now()\n",
    "                if 'h' in time_text:\n",
    "                    hours_ago = int(re.search(r'\\d{1,2}', time_text).group())\n",
    "                    published_time = current_time - timedelta(hours=hours_ago)\n",
    "                elif 'm' in time_text:\n",
    "                    minutes_ago = int(re.search(r'\\d{1,2}', time_text).group())\n",
    "                    published_time = current_time - timedelta(minutes=minutes_ago)\n",
    "                    \n",
    "                published_time_str = published_time.strftime('%I:%M %p')\n",
    "                published_date_str = published_time.strftime('%d/%m/%Y')\n",
    "                \n",
    "                data.append({'Headline': headline, 'Link': link, 'Time': time_text, 'Published Time': published_time_str, \n",
    "                             'Published Date': published_date_str, 'Source': paper, 'Category': category})\n",
    "        except Exception as e:\n",
    "            print(f\"Error extracting data from article: {e}\")\n",
    "    \n",
    "    # Close the WebDriver\n",
    "    driver.quit()\n",
    "    \n",
    "    # Create a DataFrame and save it to a CSV file\n",
    "    df = pd.DataFrame(data)\n",
    "    df.to_csv('banking_headlines.csv', index=False)\n",
    "    \n",
    "    print(df.head(20))\n",
    "    \n",
    "elif x==\"Economy\":\n",
    "    # Initialize the WebDriver\n",
    "    driver = webdriver.Chrome()\n",
    "\n",
    "    data = []\n",
    "    \n",
    "    def extract_from_daily_star():\n",
    "        driver.get(\"https://www.thedailystar.net/business/economy\")\n",
    "        time.sleep(2)\n",
    "        \n",
    "        # Define the XPath for the articles\n",
    "        article_xpath = '//div[@class=\"columns small-12 medium-3 large-3\"]'\n",
    "        \n",
    "        # Wait for the articles to be present\n",
    "        WebDriverWait(driver, 10).until(EC.presence_of_all_elements_located((By.XPATH, article_xpath)))\n",
    "        \n",
    "        # Extract data\n",
    "        articles = driver.find_elements(By.XPATH, article_xpath)\n",
    "        for article in articles:\n",
    "            try:\n",
    "                headline_element = article.find_element(By.XPATH, './/h3[@class=\"title\"]/a')\n",
    "                headline = headline_element.text\n",
    "                link = headline_element.get_attribute('href')\n",
    "                time_element = article.find_element(By.XPATH, './/div[@class=\"card-top color-iron text-12\"]/span[@class=\"interval\"]')\n",
    "                time_text = time_element.text\n",
    "                paper = \"Daily Star\"\n",
    "                category=\"Economy\"\n",
    "                if re.search(r'\\d{1,2}[hm] ago', time_text):\n",
    "                    # Calculate the published time\n",
    "                    current_time = datetime.now()\n",
    "                    if 'h' in time_text:\n",
    "                        hours_ago = int(re.search(r'\\d{1,2}', time_text).group())\n",
    "                        published_time = current_time - timedelta(hours=hours_ago)\n",
    "                    elif 'm' in time_text:\n",
    "                        minutes_ago = int(re.search(r'\\d{1,2}', time_text).group())\n",
    "                        published_time = current_time - timedelta(minutes=minutes_ago)\n",
    "                    \n",
    "                    published_time_str = published_time.strftime('%I:%M %p')\n",
    "                    published_date_str = published_time.strftime('%d/%m/%Y')\n",
    "                    \n",
    "                    data.append({'Headline': headline, 'Link': link, 'Time': time_text, 'Published Time': published_time_str, \n",
    "                                 'Published Date': published_date_str, 'Source': paper, 'Category': category})\n",
    "            except Exception as e:\n",
    "                print(f\"Error extracting data from article: {e}\")\n",
    "    \n",
    "    def extract_from_prothom_alo():\n",
    "        driver.get(\"https://en.prothomalo.com/business/local\")\n",
    "        time.sleep(2)\n",
    "        \n",
    "        try:\n",
    "            # Adjust the wait time and the locator as needed\n",
    "            close_button = WebDriverWait(driver, 20).until(\n",
    "                EC.visibility_of_element_located((By.XPATH, '//*[@id=\"pushengage-opt-in-1-close\"]'))\n",
    "            )\n",
    "            close_button.click()\n",
    "            print(\"Pop-up closed.\")\n",
    "        except:\n",
    "            print(\"No pop-up found or couldn't close the pop-up.\")\n",
    "        \n",
    "        # Define the XPath for the articles\n",
    "        article_xpath = '//div[contains(@class,\"xkXol\")]'\n",
    "                \n",
    "        # Wait for the articles to be present\n",
    "        WebDriverWait(driver, 10).until(EC.presence_of_all_elements_located((By.XPATH, article_xpath)))\n",
    "        \n",
    "        # Extract data\n",
    "        articles = driver.find_elements(By.XPATH, article_xpath)\n",
    "        for article in articles:\n",
    "            try:\n",
    "                headline_element = article.find_element(By.XPATH, './/h3/a')\n",
    "                headline = headline_element.text\n",
    "                link = headline_element.get_attribute('href')\n",
    "                time_element = article.find_element(By.XPATH, './/time')\n",
    "                time_text = time_element.text\n",
    "                paper = \"Prothom Alo\"\n",
    "                category=\"Economy\"\n",
    "                if re.search(r'\\d{1,2}\\s*(hours|minutes|hm) ago', time_text):\n",
    "                    # Calculate the published time\n",
    "                    current_time = datetime.now()\n",
    "                    if 'hours' in time_text or 'h' in time_text:\n",
    "                        hours_ago = int(re.search(r'\\d{1,2}', time_text).group())\n",
    "                        published_time = current_time - timedelta(hours=hours_ago)\n",
    "                    elif 'minutes' in time_text or 'm' in time_text:\n",
    "                        minutes_ago = int(re.search(r'\\d{1,2}', time_text).group())\n",
    "                        published_time = current_time - timedelta(minutes=minutes_ago)\n",
    "                    \n",
    "                    published_time_str = published_time.strftime('%I:%M %p')\n",
    "                    published_date_str = published_time.strftime('%d/%m/%Y')\n",
    "                    \n",
    "                    data.append({'Headline': headline, 'Link': link, 'Time': time_text, 'Published Time': published_time_str, \n",
    "                                 'Published Date': published_date_str, 'Source': paper, 'Category': category})\n",
    "            except Exception as e:\n",
    "                print(f\"Error extracting data from article: {e}\")\n",
    "    \n",
    "    # Extract data from both websites\n",
    "    extract_from_daily_star()\n",
    "    extract_from_prothom_alo()\n",
    "    \n",
    "    # Close the WebDriver\n",
    "    driver.quit()\n",
    "    \n",
    "    # Create a DataFrame and save it to a CSV file\n",
    "    df = pd.DataFrame(data)\n",
    "    df.to_csv('economy_headlines.csv', index=False)\n",
    "    \n",
    "    print(df.head(20))\n",
    "\n",
    "elif x==\"Football\":\n",
    "    # Initialize the WebDriver\n",
    "    driver = webdriver.Chrome()\n",
    "\n",
    "    data = []\n",
    "    \n",
    "    def extract_from_daily_star():\n",
    "        driver.get(\"https://www.thedailystar.net/sports/football\")\n",
    "        time.sleep(2)\n",
    "        \n",
    "        # Define the XPath for the articles\n",
    "        article_xpath = '//div[@class=\"columns small-12 medium-3 large-3\"]'\n",
    "        \n",
    "        # Wait for the articles to be present\n",
    "        WebDriverWait(driver, 10).until(EC.presence_of_all_elements_located((By.XPATH, article_xpath)))\n",
    "        \n",
    "        # Extract data\n",
    "        articles = driver.find_elements(By.XPATH, article_xpath)\n",
    "        for article in articles:\n",
    "            try:\n",
    "                headline_element = article.find_element(By.XPATH, './/h3[@class=\"title\"]/a')\n",
    "                headline = headline_element.text\n",
    "                link = headline_element.get_attribute('href')\n",
    "                time_element = article.find_element(By.XPATH, './/div[@class=\"card-top color-iron text-12\"]/span[@class=\"interval\"]')\n",
    "                time_text = time_element.text\n",
    "                paper = \"Daily Star\"\n",
    "                category=\"Football\"\n",
    "                if re.search(r'\\d{1,2}[hm] ago', time_text):\n",
    "                    # Calculate the published time\n",
    "                    current_time = datetime.now()\n",
    "                    if 'h' in time_text:\n",
    "                        hours_ago = int(re.search(r'\\d{1,2}', time_text).group())\n",
    "                        published_time = current_time - timedelta(hours=hours_ago)\n",
    "                    elif 'm' in time_text:\n",
    "                        minutes_ago = int(re.search(r'\\d{1,2}', time_text).group())\n",
    "                        published_time = current_time - timedelta(minutes=minutes_ago)\n",
    "                    \n",
    "                    published_time_str = published_time.strftime('%I:%M %p')\n",
    "                    published_date_str = published_time.strftime('%d/%m/%Y')\n",
    "                    \n",
    "                    data.append({'Headline': headline, 'Link': link, 'Time': time_text, 'Published Time': published_time_str, \n",
    "                                 'Published Date': published_date_str, 'Source': paper, 'Category': category})\n",
    "            except Exception as e:\n",
    "                print(f\"Error extracting data from article: {e}\")\n",
    "    \n",
    "    def extract_from_prothom_alo():\n",
    "        driver.get(\"https://en.prothomalo.com/sports/football\")\n",
    "        time.sleep(2)\n",
    "        \n",
    "        try:\n",
    "            # Adjust the wait time and the locator as needed\n",
    "            close_button = WebDriverWait(driver, 20).until(\n",
    "                EC.visibility_of_element_located((By.XPATH, '//*[@id=\"pushengage-opt-in-1-close\"]'))\n",
    "            )\n",
    "            close_button.click()\n",
    "            print(\"Pop-up closed.\")\n",
    "        except:\n",
    "            print(\"No pop-up found or couldn't close the pop-up.\")\n",
    "        \n",
    "        # Define the XPath for the articles\n",
    "        article_xpath = '//div[contains(@class,\"xkXol\")]'\n",
    "                \n",
    "        # Wait for the articles to be present\n",
    "        WebDriverWait(driver, 10).until(EC.presence_of_all_elements_located((By.XPATH, article_xpath)))\n",
    "        \n",
    "        # Extract data\n",
    "        articles = driver.find_elements(By.XPATH, article_xpath)\n",
    "        for article in articles:\n",
    "            try:\n",
    "                headline_element = article.find_element(By.XPATH, './/h3/a')\n",
    "                headline = headline_element.text\n",
    "                link = headline_element.get_attribute('href')\n",
    "                time_element = article.find_element(By.XPATH, './/time')\n",
    "                time_text = time_element.text\n",
    "                paper = \"Prothom Alo\"\n",
    "                category=\"Football\"\n",
    "                if re.search(r'\\d{1,2}\\s*(hours|minutes|hm) ago', time_text):\n",
    "                    # Calculate the published time\n",
    "                    current_time = datetime.now()\n",
    "                    if 'hours' in time_text or 'h' in time_text:\n",
    "                        hours_ago = int(re.search(r'\\d{1,2}', time_text).group())\n",
    "                        published_time = current_time - timedelta(hours=hours_ago)\n",
    "                    elif 'minutes' in time_text or 'm' in time_text:\n",
    "                        minutes_ago = int(re.search(r'\\d{1,2}', time_text).group())\n",
    "                        published_time = current_time - timedelta(minutes=minutes_ago)\n",
    "                    \n",
    "                    published_time_str = published_time.strftime('%I:%M %p')\n",
    "                    published_date_str = published_time.strftime('%d/%m/%Y')\n",
    "                    \n",
    "                    data.append({'Headline': headline, 'Link': link, 'Time': time_text, 'Published Time': published_time_str, \n",
    "                                 'Published Date': published_date_str, 'Source': paper, 'Category': category})\n",
    "            except Exception as e:\n",
    "                print(f\"Error extracting data from article: {e}\")\n",
    "    \n",
    "    # Extract data from both websites\n",
    "    extract_from_daily_star()\n",
    "    extract_from_prothom_alo()\n",
    "    \n",
    "    # Close the WebDriver\n",
    "    driver.quit()\n",
    "    \n",
    "    # Create a DataFrame and save it to a CSV file\n",
    "    df = pd.DataFrame(data)\n",
    "    df.to_csv('football_headlines.csv', index=False)\n",
    "    \n",
    "    print(df.head(20))\n",
    "    \n",
    "else:\n",
    "    print(\"Please write correct category. N.B: Banking, Economy, Football\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bbf9887-a0ff-4b55-921a-4fede7cd4216",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
